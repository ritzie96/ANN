{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"bindigit_trn.csv\",header=None).as_matrix()\n",
    "y_train = pd.read_csv(\"targetdigit_trn.csv\",header=None,names=[\"Label\"]).as_matrix()\n",
    "\n",
    "X_test = pd.read_csv(\"bindigit_tst.csv\",header=None).as_matrix()\n",
    "y_test = pd.read_csv(\"targetdigit_tst.csv\",header=None,names=[\"Label\"]).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Helper class for plotting images\n",
    "def plotImage(images,predictions):\n",
    "    n = 10  # how many digits we will display\n",
    "    plt.figure(figsize=(20, 4))\n",
    "    for i in range(n):\n",
    "        # display original\n",
    "        ax = plt.subplot(2, n, i + 1)\n",
    "        plt.imshow(images[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax = plt.subplot(2, n, i + 1 + n)\n",
    "        plt.imshow(predictions[i].reshape(28, 28))\n",
    "        plt.gray()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Class that defines the behavior of the RBM\n",
    "class RBM(object):\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        #Defining the hyperparameters\n",
    "        self._input_size = input_size #Size of input\n",
    "        self._output_size = output_size #Size of output\n",
    "        self.epochs = 5 #Amount of training iterations\n",
    "        self.learning_rate = 1.0 #The step used in gradient descent\n",
    "        self.batchsize = 100 #The size of how much data will be used for training per sub iteration\n",
    "        \n",
    "        #Initializing weights and biases as matrices full of zeroes\n",
    "        self.w = np.zeros([input_size, output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        self.hb = np.zeros([output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        self.vb = np.zeros([input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "\n",
    "    #Fits the result from the weighted visible layer plus the bias into a sigmoid curve\n",
    "    def prob_h_given_v(self, visible, w, hb):\n",
    "        #Sigmoid \n",
    "        return tf.nn.sigmoid(tf.matmul(visible, w) + hb)\n",
    "\n",
    "    #Fits the result from the weighted hidden layer plus the bias into a sigmoid curve\n",
    "    def prob_v_given_h(self, hidden, w, vb):\n",
    "        return tf.nn.sigmoid(tf.matmul(hidden, tf.transpose(w)) + vb)\n",
    "    \n",
    "    #Generate the sample probability\n",
    "    def sample_prob(self, probs):\n",
    "        return tf.nn.relu(tf.sign(probs - tf.random_uniform(tf.shape(probs))))\n",
    "\n",
    "    #Training method for the model\n",
    "    def train(self, X):\n",
    "        #Create the placeholders for our parameters\n",
    "        _w = tf.placeholder(\"float\", [self._input_size, self._output_size])\n",
    "        _hb = tf.placeholder(\"float\", [self._output_size])\n",
    "        _vb = tf.placeholder(\"float\", [self._input_size])\n",
    "        \n",
    "        #Previous weights and biases?\n",
    "        prv_w = np.zeros([self._input_size, self._output_size], np.float32) #Creates and initializes the weights with 0\n",
    "        prv_hb = np.zeros([self._output_size], np.float32) #Creates and initializes the hidden biases with 0\n",
    "        prv_vb = np.zeros([self._input_size], np.float32) #Creates and initializes the visible biases with 0\n",
    "\n",
    "        #Current weights and biases?\n",
    "        cur_w = np.zeros([self._input_size, self._output_size], np.float32)\n",
    "        cur_hb = np.zeros([self._output_size], np.float32)\n",
    "        cur_vb = np.zeros([self._input_size], np.float32)\n",
    "        \n",
    "        #Contrastive divergence algorithm (Steps taken from wikipedia)\n",
    "        v0 = tf.placeholder(\"float\", [None, self._input_size]) #The input vector (Step 1)\n",
    "        \n",
    "        #Initialize with sample probabilities (Step 3)\n",
    "        h0 = self.sample_prob(self.prob_h_given_v(v0, _w, _hb)) #Calculates hidden units given visible\n",
    "        v1 = self.sample_prob(self.prob_v_given_h(h0, _w, _vb)) #(Re-?)Calculates visible units given hidden\n",
    "        h1 = self.prob_h_given_v(v1, _w, _hb) #Again calculate hidden from visible, but no sampling\n",
    "        \n",
    "        #Create the Gradients\n",
    "        positive_grad = tf.matmul(tf.transpose(v0), h0) #(Step 2)\n",
    "        negative_grad = tf.matmul(tf.transpose(v1), h1) #(Step 4)\n",
    "        \n",
    "        #Update learning rates for the layers ??? (You mean weights and biases)\n",
    "        update_w = _w + self.learning_rate *(positive_grad - negative_grad) / tf.to_float(tf.shape(v0)[0]) #(Step 5 with som normalization)\n",
    "        update_vb = _vb +  self.learning_rate * tf.reduce_mean(v0 - v1, 0)\n",
    "        update_hb = _hb +  self.learning_rate * tf.reduce_mean(h0 - h1, 0)\n",
    "        \n",
    "        #Find the error rate\n",
    "        err = tf.reduce_mean(tf.square(v0 - v1))\n",
    "        \n",
    "        #Training loop\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            #For each epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                #For each step/batch\n",
    "                for start, end in zip(range(0, len(X), self.batchsize),range(self.batchsize,len(X), self.batchsize)):\n",
    "                    batch = X[start:end]\n",
    "                    #Update the rates\n",
    "                    cur_w = sess.run(update_w, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_hb = sess.run(update_hb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    cur_vb = sess.run(update_vb, feed_dict={v0: batch, _w: prv_w, _hb: prv_hb, _vb: prv_vb})\n",
    "                    prv_w = cur_w\n",
    "                    prv_hb = cur_hb\n",
    "                    prv_vb = cur_vb\n",
    "                error=sess.run(err, feed_dict={v0: X, _w: cur_w, _vb: cur_vb, _hb: cur_hb})\n",
    "                print('Epoch: %d' % epoch,'reconstruction error: %f' % error)\n",
    "            self.w = prv_w\n",
    "            self.hb = prv_hb\n",
    "            self.vb = prv_vb\n",
    "\n",
    "    #Create expected output for our DBN\n",
    "    def rbm_outpt(self, X):\n",
    "        input_X = tf.constant(X)\n",
    "        _w = tf.constant(self.w)\n",
    "        _hb = tf.constant(self.hb)\n",
    "        out = tf.nn.sigmoid(tf.matmul(input_X, _w) + _hb)\n",
    "        reconstruct = self.prob_v_given_h(out,self.w,self.vb)\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            return sess.run(out),sess.run(reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:170: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Epoch: 0 reconstruction error: 0.115999\n",
      "Epoch: 1 reconstruction error: 0.101300\n",
      "Epoch: 2 reconstruction error: 0.095040\n",
      "Epoch: 3 reconstruction error: 0.092484\n",
      "Epoch: 4 reconstruction error: 0.090484\n"
     ]
    }
   ],
   "source": [
    "input_size = 784\n",
    "output_size = 50\n",
    "rbm = RBM(input_size, output_size)\n",
    "\n",
    "rbm.train(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'a' has DataType int64 not in list of allowed values: float16, float32, float64, int32, complex64, complex128",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-86dc35be1b5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Return the output layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreconstruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrbm_outpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-fa72617a9eeb>\u001b[0m in \u001b[0;36mrbm_outpt\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0m_w\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0m_hb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0m_hb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mreconstruct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprob_v_given_h\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   1814\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1815\u001b[0m       return gen_math_ops._mat_mul(\n\u001b[1;32m-> 1816\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1817\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m_mat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   1215\u001b[0m   \"\"\"\n\u001b[0;32m   1216\u001b[0m   result = _op_def_lib.apply_op(\"MatMul\", a=a, b=b, transpose_a=transpose_a,\n\u001b[1;32m-> 1217\u001b[1;33m                                 transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   1218\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    587\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    588\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 589\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    590\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'a' has DataType int64 not in list of allowed values: float16, float32, float64, int32, complex64, complex128"
     ]
    }
   ],
   "source": [
    "#Return the output layer\n",
    "output,reconstruct = rbm.rbm_outpt(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAC01JREFUeJzt3V+opHUZwPHvk627uBYotttmW5ZI\nJEJbHNbACEOsLYK1i8S9iA2i44VCQReJN3kTSGTlRQhrLm3gXyhzL6SSJbAgxKOIq22lyKbbLnuK\nDbSg9d/TxXlXjus5Z2Zn3nfeOef5fkDOzJw5Zx4Gv/vOnN/M/CIzkVTPu/oeQFI/jF8qyvilooxf\nKsr4paKMXyrK+KWijF8qyvilot49yRs7O9bnBjZO8ialUv7Hf3k1T8Yw1x0r/ojYAdwOnAX8LDNv\nXen6G9jI5XHVODcpaQWP5YGhrzvyw/6IOAv4KfBF4FJgV0RcOurvkzRZ4zzn3w48n5kvZOarwH3A\nznbGktS1ceK/EHhp0fkjzWVvExGzETEXEXOvcXKMm5PUpnHiX+qPCu94f3Bm7snMmcycWcf6MW5O\nUpvGif8IsHXR+Q8CR8cbR9KkjBP/48AlEfGRiDgbuA7Y385Ykro28lJfZr4eETcCv2VhqW9vZj7b\n2mSSOjXWOn9mPgw83NIskibIl/dKRRm/VJTxS0UZv1SU8UtFGb9UlPFLRRm/VJTxS0UZv1SU8UtF\nGb9UlPFLRU30o7u19vz26FMj/+wXPrCtxUl0pjzyS0UZv1SU8UtFGb9UlPFLRRm/VJTxS0W5zq8V\njbOOr+nmkV8qyvilooxfKsr4paKMXyrK+KWijF8qaqx1/og4DLwCvAG8npkzbQylyXEdv642XuTz\nucz8Vwu/R9IE+bBfKmrc+BP4XUQ8ERGzbQwkaTLGfdh/RWYejYhNwCMR8ZfMfHTxFZp/FGYBNnDO\nmDcnqS1jHfkz82jzdR54ENi+xHX2ZOZMZs6sY/04NyepRSPHHxEbI+I9p04DnweeaWswSd0a52H/\nZuDBiDj1e+7JzN+0MpWkzo0cf2a+AHyixVnUgb7X8f1s/unlUp9UlPFLRRm/VJTxS0UZv1SU8UtF\n+dHdGotLeauXR36pKOOXijJ+qSjjl4oyfqko45eKMn6pKNf514Au37brOv7a5ZFfKsr4paKMXyrK\n+KWijF8qyvilooxfKsp1/uJcx6/LI79UlPFLRRm/VJTxS0UZv1SU8UtFGb9U1MB1/ojYC3wZmM/M\ny5rLzgfuBy4CDgPXZua/uxtzbet7G23VNMyR/+fAjtMuuwk4kJmXAAea85JWkYHxZ+ajwInTLt4J\n7GtO7wOuaXkuSR0b9Tn/5sw8BtB83dTeSJImofPX9kfELDALsIFzur45SUMa9ch/PCK2ADRf55e7\nYmbuycyZzJxZx/oRb05S20aNfz+wuzm9G3ionXEkTcrA+CPiXuBPwMci4khEfAO4Fbg6Ip4Drm7O\nS1pFBj7nz8xdy3zrqpZnUQem+f36g17fMM2zrwW+wk8qyvilooxfKsr4paKMXyrK+KWi/OjuCejz\nLbur+e3Cbj3eLY/8UlHGLxVl/FJRxi8VZfxSUcYvFWX8UlGu86sk307skV8qy/ilooxfKsr4paKM\nXyrK+KWijF8qyvilooxfKsr4paKMXyrK+KWijF8qyvilooxfKmrg+/kjYi/wZWA+My9rLrsF+Cbw\nz+ZqN2fmw10Nqe6s5vetd/m5/hXe7z/Mkf/nwI4lLv9xZm5r/jN8aZUZGH9mPgqcmMAskiZonOf8\nN0bE0xGxNyLOa20iSRMxavx3ABcD24BjwG3LXTEiZiNiLiLmXuPkiDcnqW0jxZ+ZxzPzjcx8E7gT\n2L7Cdfdk5kxmzqxj/ahzSmrZSPFHxJZFZ78CPNPOOJImZZilvnuBK4ELIuII8D3gyojYBiRwGLi+\nwxkldWBg/Jm5a4mL7+pgFnVgLaxHqxu+wk8qyvilooxfKsr4paKMXyrK+KWi3KJ7DXA5T6PwyC8V\nZfxSUcYvFWX8UlHGLxVl/FJRxi8V5Tr/KrBW1/G7/OjtQdbqfXomPPJLRRm/VJTxS0UZv1SU8UtF\nGb9UlPFLRbnOvwqMsx4+7np2n2vx43Itf2Ue+aWijF8qyvilooxfKsr4paKMXyrK+KWiBq7zR8RW\n4BfA+4E3gT2ZeXtEnA/cD1wEHAauzcx/dzeqRrGa1+kHcR1/PMMc+V8HvpOZHwc+DdwQEZcCNwEH\nMvMS4EBzXtIqMTD+zDyWmU82p18BDgEXAjuBfc3V9gHXdDWkpPad0XP+iLgI+CTwGLA5M4/Bwj8Q\nwKa2h5PUnaHjj4hzgV8C387Ml8/g52YjYi4i5l7j5CgzSurAUPFHxDoWwr87M3/VXHw8IrY0398C\nzC/1s5m5JzNnMnNmHevbmFlSCwbGHxEB3AUcyswfLfrWfmB3c3o38FD740nqSmTmyleI+AzwB+Ag\nC0t9ADez8Lz/AeBDwIvAVzPzxEq/671xfl4eV40785qzlpfjxuFS3pl7LA/wcp6IYa47cJ0/M/8I\nLPfLLFlapXyFn1SU8UtFGb9UlPFLRRm/VJTxS0X50d1TYNB69mp+HYBr9dPLI79UlPFLRRm/VJTx\nS0UZv1SU8UtFGb9UlOv8q4Br5eqCR36pKOOXijJ+qSjjl4oyfqko45eKMn6pKOOXijJ+qSjjl4oy\nfqko45eKMn6pKOOXijJ+qaiB8UfE1oj4fUQciohnI+JbzeW3RMQ/IuKp5r8vdT+upLYM82EerwPf\nycwnI+I9wBMR8UjzvR9n5g+7G09SVwbGn5nHgGPN6Vci4hBwYdeDSerWGT3nj4iLgE8CjzUX3RgR\nT0fE3og4b5mfmY2IuYiYe42TYw0rqT1Dxx8R5wK/BL6dmS8DdwAXA9tYeGRw21I/l5l7MnMmM2fW\nsb6FkSW1Yaj4I2IdC+HfnZm/AsjM45n5Rma+CdwJbO9uTEltG+av/QHcBRzKzB8tunzLoqt9BXim\n/fEkdWWYv/ZfAXwNOBgRp/aKvhnYFRHbgAQOA9d3MqGkTgzz1/4/ArHEtx5ufxxJk+Ir/KSijF8q\nyvilooxfKsr4paKMXyrK+KWijF8qyvilooxfKsr4paKMXyrK+KWijF8qKjJzcjcW8U/g74suugD4\n18QGODPTOtu0zgXONqo2Z/twZr5vmCtONP533HjEXGbO9DbACqZ1tmmdC5xtVH3N5sN+qSjjl4rq\nO/49Pd/+SqZ1tmmdC5xtVL3M1utzfkn96fvIL6knvcQfETsi4q8R8XxE3NTHDMuJiMMRcbDZeXiu\n51n2RsR8RDyz6LLzI+KRiHiu+brkNmk9zTYVOzevsLN0r/fdtO14PfGH/RFxFvA34GrgCPA4sCsz\n/zzRQZYREYeBmczsfU04Ij4L/Af4RWZe1lz2A+BEZt7a/MN5XmZ+d0pmuwX4T987NzcbymxZvLM0\ncA3wdXq871aY61p6uN/6OPJvB57PzBcy81XgPmBnD3NMvcx8FDhx2sU7gX3N6X0s/M8zccvMNhUy\n81hmPtmcfgU4tbN0r/fdCnP1oo/4LwReWnT+CNO15XcCv4uIJyJitu9hlrC52Tb91Pbpm3qe53QD\nd26epNN2lp6a+26UHa/b1kf8S+3+M01LDldk5qeALwI3NA9vNZyhdm6elCV2lp4Ko+543bY+4j8C\nbF10/oPA0R7mWFJmHm2+zgMPMn27Dx8/tUlq83W+53neMk07Ny+1szRTcN9N047XfcT/OHBJRHwk\nIs4GrgP29zDHO0TExuYPMUTERuDzTN/uw/uB3c3p3cBDPc7yNtOyc/NyO0vT8303bTte9/Iin2Yp\n4yfAWcDezPz+xIdYQkR8lIWjPSxsYnpPn7NFxL3AlSy86+s48D3g18ADwIeAF4GvZubE//C2zGxX\nsvDQ9a2dm089x57wbJ8B/gAcBN5sLr6ZhefXvd13K8y1ix7uN1/hJxXlK/ykooxfKsr4paKMXyrK\n+KWijF8qyvilooxfKur/9gtS/uXnQ5sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22865399828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'reconstruct' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-7ca95152b1b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reconstruct' is not defined"
     ]
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28, 28))\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(reconstruct[0].reshape(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
